[Doc link](https://drive.xttech.tech/s/NPAJkjMi7eQJYpS)

Treadmill Paper:

[https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7551414&tag=1](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7551414&tag=1)

https://github.com/facebook/treadmill

What Treadmill is:



*   “a modular software load tester (Section III-A), and a robust procedure for tail latency measurement (Section III-B).”

Background concepts:



1. Closed Loop vs Open Loop
    *   Closed Loop systems involve a type of queue where new requests have to wait for older requests to complete
    *   Open loop systems involve independent requests that can arrive and be handled regardless of completion of other requests
        *   Most server/cloud based systems work in this style
2. 4 Pitfalls of load testing tools
    *   Query Inter-arrival Generation
        *   Many load testers have an implicit closed loop system assumption which does not align with modern typical systems that tail latency is important to consider for, most systems are in an open-loop configuration. 
        *   This is a problem because the data generated by typical load testers will not be fully representative of modern systems
    *   Statistical aggregation
        *   Improper representation of data such as representing 95th or 99th percentile latency as a single point which means a lot of information about this region of performance is lost and thus not well represented.
    *   Client-Side queueing bias
        *   Typically multiple clients are needed to handle the incredibly high throughput of modern systems this leads to a situation where overhead of clients can begin to have a large impact on performance and thus skews data.
    *   Performance “Hysteresis”
        *   Variation in estimated overall/average latency across tests which is due to variation in how the underlying hardware is used, has been shown to be impossible or highly inefficient to prevent in a reasonable amount of time/samples
3. Treadmill’s Implementation
    *   Query Inter-Arrival Generation Solution
        *   Implemented an Open-Loop Controller
        *   “The control loop is precisely timed to generate requests at an exponentially distributed inter-arrival rate”
            *   This is to simulate an open loop system since open loop systems often will have an incredibly large number of requests to handle at any given time. 
            *   “is consistent with the measurements obtained from Google production clusters [1].”
    *   Statistical Aggregation Solution
        *   Makes use of Histograms
            *   Useful for reducing storage and performance overhead
            *   Rebinned when sufficient amount of values exceed histogram limits
        *   3 Phases
            *   Warm-Up
                *   Discards all measured samples at the start
            *   Calibration
                *   Determines Lower and Upper bounds of sample histogram bins
                *   “reduce the amount of information lost from transforming detailed latency samples into a histogram”
            *   Measurement
                *   Collect samples until end of execution
    *   Client-side queueing bias solution
        *   Makes use of the tool Wangle
            *   Provides inline execution of callback function
            *   “ensure that the response callback logic is executed immediately when the response is available”
            *   This reduces client-side queueing bias since we reduce the amount of time the client has to wait by making it immediately execute the callback function once the response if available
        *   Tried to highly optimize the performance like using a lock-free implementation
            *   This reduces client-side queueing bias due to consistent low utilization from clientes
    *   Generality
        *   Separately integrated with other services such as memcached and mcrouter
        *   These integrations generally took less than 200 lines of code
    *   Configurable workload
        *   The type of workload has a big impact on system performance
        *   Thus they designed Treadmill to be able to accept different types of workloads to send to the tested application via a JSON file
    *   Tail Latency measurement
        *   Uses multiple instances of the Treadmill tool to send a portion of the desired throughput to the same server
        *   Repeats this multiple times and gathers measurements each time
        *   Aggregates all of the measurements to produce a converged estimate
        *   Computes each of the metrics we’re interested like 99th percentile or 95th percentile latency for each Treadmill instance then it aggregates the data 
        *   Repeats the experiment until the mean of the measurements converges